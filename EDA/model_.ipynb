{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LeakyReLU\n",
    "from keras.layers import LSTM ,Bidirectional\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.metrics import r2_score\n",
    "from keras.regularizers import L1L2\n",
    "from tensorflow.keras.models import load_model\n",
    "from numpy.random import seed\n",
    "\n",
    "\n",
    "\n",
    "class LSTM_Model():\n",
    "    seed(42)\n",
    "    tf.random.set_seed(42)  \n",
    "    def __init__(self, dataframe, window_size, lags, trainsize):\n",
    "\n",
    "        self.dataframe = dataframe\n",
    "        self.window_size = window_size\n",
    "        self.lags = lags\n",
    "        self.trainsize = trainsize\n",
    "\n",
    "    # moving average calculation\n",
    "    def moving_average(self):\n",
    "        \n",
    "        \n",
    "        i = 0\n",
    "        moving_averages = []\n",
    "        while i < len(self.dataframe['Total']) - self.window_size + 1:\n",
    "            this_window = self.dataframe['Total'][i : i + self.window_size]\n",
    "            window_average = sum(this_window) / self.window_size\n",
    "            moving_averages.append(window_average)\n",
    "            i += 1\n",
    "        sales = pd.DataFrame(moving_averages, columns=['Total'])\n",
    "        # sales_norm = scaler.fit_transform(sales.Total.values.reshape(-1, 1))\n",
    "        # sales['sales_norm'] = sales_norm\n",
    "        # sales = sales.drop(['Total'],axis = 1)\n",
    "        return sales\n",
    "\n",
    "    def scaled(self):\n",
    "        scaler = MinMaxScaler()\n",
    "        sales = self.moving_average()\n",
    "        sales_norm = scaler.fit_transform(sales.Total.values.reshape(-1, 1))\n",
    "        sales['sales_norm'] = sales_norm\n",
    "        sales = sales.drop(['Total'],axis = 1)\n",
    "        return sales\n",
    "\n",
    "    #adding lag to the sales for multistep forecasting\n",
    "    def lags_cal(self):\n",
    "\n",
    "        sales = self.scaled()\n",
    "        for lag in range(1,self.lags):\n",
    "            col_name = 'lag_' +str(lag)\n",
    "            sales[col_name] = sales['sales_norm'].shift(lag)\n",
    "        #drop null val\n",
    "        sales = sales.dropna().reset_index(drop = True)\n",
    "        return sales\n",
    "\n",
    "    # tain and test dataset\n",
    "    def split_train_test(self):\n",
    "\n",
    "        \"\"\" This function splits the dataframe in to train and test sets and converts in to LSTM readable format\n",
    "        It needs 2 input: \n",
    "            1. Dataframe to split the dta into train and test\n",
    "            2. trainsize in percentage ratio.\n",
    "                eg: if you want 80% of the data as training then plug in 0.8\"\"\"\n",
    "\n",
    "        sales = self.lags_cal()\n",
    "        train = sales[: int(len(sales)*self.trainsize)].values\n",
    "        test =  sales[int(len(sales)*self.trainsize):].values\n",
    "        X_train = train[:, 1:]\n",
    "        y_train = train[:, 0:1]\n",
    "        X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "        X_test = test[:, 1:]\n",
    "        y_test = test[:, 0:1]\n",
    "        X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "        return X_train, y_train, X_test, y_test\n",
    "\n",
    "    def build_LSTM(self):\n",
    "\n",
    "        X_train, y_train, X_test, y_test = self.split_train_test()\n",
    "        K.clear_session()\n",
    "        model = Sequential()\n",
    "        model.add(Bidirectional(LSTM(64, activation = 'tanh', \n",
    "                                input_shape = ( X_train.shape[1], X_train.shape[2]), \n",
    "                                return_sequences=True)))\n",
    "        model.add(Bidirectional(LSTM(32, activation = 'tanh', \n",
    "                                return_sequences = False)))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(50, activation = 'tanh'))\n",
    "        model.add(Dense(y_train.shape[1]))\n",
    "\n",
    "        return model\n",
    "\n",
    "    # fit the model\n",
    "    def fit_evaluate_model(self):\n",
    "        \n",
    "        \"\"\" This function prints all the epochs, loss and val score plot and also\n",
    "        evaluation score on test data and return the fitmodel as 'mod', \n",
    "        which also can be used in to function (evaluate_model)\"\"\"\n",
    "\n",
    "        X_train, y_train, X_test, y_test = self.split_train_test()\n",
    "        mod = self.build_LSTM()\n",
    "        mod.compile(optimizer='adam', loss='mse')\n",
    "        cb = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                    min_delta=0.01,\n",
    "                                    patience=100,\n",
    "                                    verbose=1,\n",
    "                                    mode=\"min\",\n",
    "                                    baseline=None,\n",
    "                                    restore_best_weights=False)\n",
    "        history = mod.fit(X_train,y_train, \n",
    "                    epochs = 500, \n",
    "                    batch_size = 8, \n",
    "                    validation_split=0.2, \n",
    "                    verbose = 1,\n",
    "                    callbacks=[cb],\n",
    "                    shuffle= True)\n",
    "        pd.DataFrame(history.history).plot()\n",
    "        plt.grid(True)\n",
    "        plt.gca() # set the y range to [0,1]\n",
    "        plt.show()\n",
    "        print('\\n')\n",
    "        print('*****************************************')\n",
    "        print('\\n')\n",
    "        print('Model Evalution Score')\n",
    "        print(mod.evaluate(X_test, y_test)) \n",
    "        return mod\n",
    "        \n",
    "    # model evaluation\n",
    "    def evaluate_model(self,mod):\n",
    "\n",
    "        X_train, y_train, X_test, y_test = self.split_train_test()\n",
    "        print(mod.evaluate(X_test, y_test)) \n",
    "        \n",
    "    \"\"\" How to run:\n",
    "    sales_pred = LSTM_Model(sales_, 4, 6, 0.9)\n",
    "    model = sales_pred.fit_evaluate_model()\n",
    "\n",
    "    the below code is not necessary: \n",
    "    \n",
    "    sales_pred.evaluate_model(model)   \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_tot = pd.read_csv('./data/sales_full.csv', index_col=0)\n",
    "#sales_tot.head()\n",
    "sales_tot = sales_tot.drop(['year','week','weeks'], axis = 1)\n",
    "sales_ = sales_tot.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 8s 128ms/step - loss: 0.1156 - val_loss: 0.0583\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0388 - val_loss: 0.0093\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0363 - val_loss: 0.0085\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0247 - val_loss: 0.0120\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0226 - val_loss: 0.0077\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0192 - val_loss: 0.0074\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0202 - val_loss: 0.0067\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0147 - val_loss: 0.0066\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0123 - val_loss: 0.0044\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0120 - val_loss: 0.0040\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0123 - val_loss: 0.0035\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0105 - val_loss: 0.0031\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0132 - val_loss: 0.0027\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.0147 - val_loss: 0.0123\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0116 - val_loss: 0.0040\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.0122 - val_loss: 0.0063\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0115 - val_loss: 0.0025\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.0131 - val_loss: 0.0042\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0117 - val_loss: 0.0035\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0107 - val_loss: 0.0020\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0093 - val_loss: 0.0024\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0089 - val_loss: 0.0023\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0022\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0022\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0081 - val_loss: 0.0020\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0113 - val_loss: 0.0041\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0098 - val_loss: 0.0019\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0079 - val_loss: 0.0021\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0101 - val_loss: 0.0019\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0124 - val_loss: 0.0017\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0050\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0096 - val_loss: 0.0030\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0104 - val_loss: 0.0025\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0020\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0017\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0054\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0021\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0018\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0109 - val_loss: 0.0036\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0099 - val_loss: 0.0024\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0112 - val_loss: 0.0016\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0094 - val_loss: 0.0035\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0015\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0095 - val_loss: 0.0016\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0090 - val_loss: 0.0016\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0023\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0018\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0027\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0024\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0028\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0023\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0078 - val_loss: 0.0017\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0038\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0095 - val_loss: 0.0019\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0022\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0066 - val_loss: 0.0016\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0018\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0020\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0091 - val_loss: 0.0028\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0075 - val_loss: 0.0018\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0015\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0069 - val_loss: 0.0022\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0075 - val_loss: 0.0030\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0016\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0017\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0014\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0086 - val_loss: 0.0031\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0026\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0071 - val_loss: 0.0036\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0028\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0079 - val_loss: 0.0024\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0015\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0080 - val_loss: 0.0018\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0091 - val_loss: 0.0016\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0013\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0070 - val_loss: 0.0016\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0083 - val_loss: 0.0025\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0072 - val_loss: 0.0016\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0018\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0077 - val_loss: 0.0015\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0081 - val_loss: 0.0019\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0072 - val_loss: 0.0017\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0088 - val_loss: 0.0023\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0090 - val_loss: 0.0042\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0085 - val_loss: 0.0028\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0105 - val_loss: 0.0094\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0087 - val_loss: 0.0018\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0077 - val_loss: 0.0027\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0082 - val_loss: 0.0017\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0100 - val_loss: 0.0018\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0084 - val_loss: 0.0018\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0092 - val_loss: 0.0027\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0016\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0076 - val_loss: 0.0017\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0084 - val_loss: 0.0015\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0080 - val_loss: 0.0015\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 0.0075 - val_loss: 0.0016\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0085 - val_loss: 0.0018\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0089 - val_loss: 0.0021\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0088 - val_loss: 0.0021\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 0.0083 - val_loss: 0.0028\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 0.0093 - val_loss: 0.0015\n",
      "Epoch 102: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****************************************\n",
      "\n",
      "\n",
      "Model Evalution Score\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0041\n",
      "0.004059961996972561\n"
     ]
    }
   ],
   "source": [
    "sales_pred = LSTM_Model(sales_, 4, 6, 0.9)\n",
    "history = sales_pred.fit_evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.0041\n",
      "0.004059961996972561\n"
     ]
    }
   ],
   "source": [
    "sales_pred.evaluate_model(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving average calculation\n",
    "def moving_average(dataframe, window_size):\n",
    "    \n",
    "    window_size = 4\n",
    "    #tot = sales['Total].tolist()\n",
    "    i = 0\n",
    "    moving_averages = []\n",
    "    while i < len(dataframe['Total']) - window_size + 1:\n",
    "        this_window = dataframe['Total'][i : i + window_size]\n",
    "        window_average = sum(this_window) / window_size\n",
    "        moving_averages.append(window_average)\n",
    "        i += 1\n",
    "\n",
    "    sales = pd.DataFrame(moving_averages, columns=['Total'])\n",
    "    return sales\n",
    "\n",
    "#adding lag to the sales for multistep forecasting\n",
    "def lags(dataframe, lags):\n",
    "    for lag in range(1,lags):\n",
    "        col_name = 'lag_' +str(lag)\n",
    "        dataframe[col_name] = dataframe['sales_norm'].shift(lag)\n",
    "    #drop null val\n",
    "    dataframe = dataframe.dropna().reset_index(drop = True)\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def forecasting(dataframe, window_size, lag, n_future):\n",
    "    \n",
    "    #dataframe = sales_\n",
    "    #window_size = 4\n",
    "    #lags = 6\n",
    "    #n_future = number of weeks /days to forecast in future\n",
    "\n",
    "    model = load_model(r'.\\models\\model_final.h5') \n",
    "    scaler = MinMaxScaler()\n",
    "    for n in range(n_future):\n",
    "    \n",
    "        sales = pd.DataFrame(moving_average(dataframe, window_size), columns=['Total'])\n",
    "        sales_norm = scaler.fit_transform(sales.Total.values.reshape(-1, 1))\n",
    "        sales_norm = sales_norm.flatten().tolist()\n",
    "        sales['sales_norm'] = sales_norm\n",
    "        sales = sales.drop(['Total'],axis = 1)\n",
    "        sales = lags(sales,lag)\n",
    "        last_row = sales[-1:]\n",
    "        last_row = last_row.drop(['sales_norm'], axis = 1)\n",
    "        last_row = last_row.to_numpy()\n",
    "        last_row = last_row.reshape(last_row.shape[0], 1, last_row.shape[1])\n",
    "        pred = model.predict(last_row)\n",
    "        forecast = scaler.inverse_transform(pred)[:,0]#.tolist()\n",
    "        forecast = pd.DataFrame(forecast, columns = ['Total'])\n",
    "        dataframe = pd.concat([dataframe, forecast], ignore_index=True)\n",
    "    print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Total\n",
      "0    37640.000000\n",
      "1    19520.000000\n",
      "2     1270.000000\n",
      "3     2700.000000\n",
      "4     3560.000000\n",
      "..            ...\n",
      "154  47352.722656\n",
      "155  47270.066406\n",
      "156  47550.515625\n",
      "157  47840.859375\n",
      "158  48008.507812\n",
      "\n",
      "[159 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "forecasting(sales_, 4,6, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "17097eb73632920645ea3f57aadf8dce6f480a6176ed0d94273968eaca5554a4"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('deepL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
